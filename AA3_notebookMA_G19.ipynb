{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081c3706",
   "metadata": {
    "id": "081c3706"
   },
   "source": [
    "# DATA STREAMING AND SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8676528b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "8676528b",
    "outputId": "d8ade5e1-7d3f-406a-9996-62639882f10c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width: 95% ! important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width: 95% ! important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7cb01a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fc7cb01a",
    "outputId": "e2d0b7f9-ff23-4a44-db86-0d4356b12024"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DidierC.lan:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c821dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "12c821dc",
    "outputId": "9cd7dc41-15b3-4107-b843-e6088c4371f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DidierC.lan:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1637b3a6130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb0872",
   "metadata": {
    "id": "a8cb0872"
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c746b36",
   "metadata": {
    "id": "7c746b36"
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc,10)\n",
    "\n",
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10659f8d",
   "metadata": {
    "id": "10659f8d"
   },
   "outputs": [],
   "source": [
    "lines.saveAsTextFiles(\"file:///C:/Users/didie/OneDrive/Bureaublad/spark/TrainingData/TrainingData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55f4cc",
   "metadata": {
    "id": "ee55f4cc"
   },
   "outputs": [],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee7c23",
   "metadata": {
    "id": "d7ee7c23"
   },
   "outputs": [],
   "source": [
    "# Wait a bit before running this cell until you see output appear in the previous cell\n",
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1be772",
   "metadata": {
    "id": "3b1be772"
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"file:///C:/Users/didie/OneDrive/Bureaublad/spark/TrainingData/TrainingData-*\")\n",
    "## Didier: ik heb problemen om de data op deze manier in te lezen\n",
    "## FYI: ik lees data in in mapje trainingdata met alle bestanden met naam TrainingData-... - hiervoor dient asterix in commando zodat we alles in 1 keer kunnen doen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94347f1e",
   "metadata": {
    "id": "94347f1e"
   },
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73018b8",
   "metadata": {
    "id": "b73018b8"
   },
   "outputs": [],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b77e7",
   "metadata": {
    "id": "486b77e7"
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23931c8",
   "metadata": {
    "id": "a23931c8"
   },
   "outputs": [],
   "source": [
    "df.show()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7aa5e",
   "metadata": {
    "id": "74f7aa5e"
   },
   "outputs": [],
   "source": [
    "## DataFrame aanmaken via pandas\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_csv(\"file:///C:/Users/didie/OneDrive/Bureaublad/AA/all_data_extra.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "myOeMWEwSUnQ",
   "metadata": {
    "id": "myOeMWEwSUnQ"
   },
   "outputs": [],
   "source": [
    "## DataFrame aanmaken via Spark zodat MLIB Package werkt:\n",
    "spark = SparkSession.builder.appName(\"new\").getOrCreate()\n",
    "df = (spark.read.format(\"csv\").option('header', 'true').load(\"file:///C:/Users/didie/OneDrive/Bureaublad/AA/all_data_extra.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49f7aa",
   "metadata": {
    "id": "cf49f7aa"
   },
   "source": [
    "# PREDICTIVE MODEL A - USING MLIB\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e2dc74",
   "metadata": {
    "id": "c0e2dc74"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"text-label\", pattern=\"\\\\W\")\n",
    "\n",
    "# stop words are based upon NLTK - https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a\n",
    "add_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"text-label\", outputCol=\"text-cleaned\").setStopWords(add_stopwords)\n",
    "\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"text-cleaned\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "# IDF \n",
    "idf = IDF(inputCol=\"features\", outputCol=\"featuresIDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mieq5x8wsuTE",
   "metadata": {
    "id": "mieq5x8wsuTE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         review_text|\n",
      "+--------------------+\n",
      "|10000000000000000...|\n",
      "|A Raft style surv...|\n",
      "| resources might ...|\n",
      "| and then it wasn...|\n",
      "| access your craf...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"review_text\").na.drop().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1msBHErCsugz",
   "metadata": {
    "id": "1msBHErCsugz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+\n",
      "|count(CASE WHEN (isnan(review_text) OR (review_text IS NULL)) THEN true END)|\n",
      "+----------------------------------------------------------------------------+\n",
      "|                                                                        1682|\n",
      "+----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(col(\"review_text\")) | col(\"review_text\").isNull(), True))]).show()\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b7a346",
   "metadata": {
    "id": "e2b7a346"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"label\", outputCol = \"label_code\", handleInvalid=\"keep\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"featuresIDF\"], outputCol=\"features_combined\")\n",
    "\n",
    "logreg = LogisticRegression(maxIter=10, regParam=0.2, elasticNetParam=0, labelCol=\"label_code\", featuresCol=\"featuresIDF\")\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, idf, label_stringIdx, logreg, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ad3392",
   "metadata": {
    "id": "60ad3392"
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "QsDGyez3BfJX",
   "metadata": {
    "id": "QsDGyez3BfJX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+--------------------+\n",
      "|           review_id|              app_id|         review_text|               label|          text-label|        text-cleaned|            features|         featuresIDF|label_code|       rawPrediction|         probability|prediction|   features_combined|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+--------------------+\n",
      "|(Don't let your m...| asking if you're...|      I am winning)\"|                   1|    [i, am, winning]|           [winning]|         (418,[],[])|         (418,[],[])|       0.0|[5.85514010630536...|[0.46021023950044...|       0.0|         (418,[],[])|\n",
      "|(and from what I'...| the devs don't s...| so I'm not sure ...| which is a huge ...|[so, i, m, not, s...|[sure, long, one,...|(418,[5,93,101,32...|(418,[5,93,101,32...|     333.0|[5.86274538701756...|[0.47039443038100...|       0.0|(418,[5,93,101,32...|\n",
      "|* I have discover...| golden era of ho...|          W. Gretzky| B.Shanahan and s...|        [w, gretzky]|        [w, gretzky]|         (418,[],[])|         (418,[],[])|     333.0|[5.85514010630536...|[0.46021023950044...|       0.0|         (418,[],[])|\n",
      "|* More achievemen...| scoring goals wi...| experimenting wi...| overcoming weak ...|[experimenting, w...|[experimenting, d...|         (418,[],[])|         (418,[],[])|     333.0|[5.85514010630536...|[0.46021023950044...|       0.0|         (418,[],[])|\n",
      "|- Bosses are hard...| the problem is n...| the problem is t...| specially if you...|[the, problem, is...|[problem, challen...|(418,[32,47,71,16...|(418,[32,47,71,16...|     333.0|[6.56185564004025...|[0.62054628367004...|       0.0|(418,[32,47,71,16...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(train)\n",
    "predictions = pipelineFit.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd448f6c",
   "metadata": {
    "id": "dd448f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3693371517384297"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_code\", predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844700f7",
   "metadata": {
    "id": "844700f7"
   },
   "outputs": [],
   "source": [
    "eval_accuracy = MulticlassClassificationEvaluator(labelCol=\"label_code\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "eval_precision = MulticlassClassificationEvaluator(labelCol=\"label_code\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "eval_recall = MulticlassClassificationEvaluator(labelCol=\"label_code\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "eval_f1 = MulticlassClassificationEvaluator(labelCol=\"label_code\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e58511",
   "metadata": {
    "id": "67e58511"
   },
   "outputs": [],
   "source": [
    "accuracy = eval_accuracy.evaluate(predictions)\n",
    "precision = eval_precision.evaluate(predictions)\n",
    "recall = eval_recall.evaluate(predictions)\n",
    "f1score = eval_f1.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "141d3e4a",
   "metadata": {
    "id": "141d3e4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5145348837209303"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0303a239",
   "metadata": {
    "id": "0303a239"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33850049838421936"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb3884f7",
   "metadata": {
    "id": "eb3884f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5145348837209303"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed213ae5",
   "metadata": {
    "id": "ed213ae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3693371517384297"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1e7b4",
   "metadata": {
    "id": "04e1e7b4"
   },
   "source": [
    "# MODEL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71e17195",
   "metadata": {
    "id": "71e17195"
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5011871e",
   "metadata": {
    "id": "5011871e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DidierC.lan:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a832cb62",
   "metadata": {
    "id": "a832cb62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DidierC.lan:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1637b3a6130>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd40a85",
   "metadata": {
    "id": "cfd40a85"
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b2e794",
   "metadata": {
    "id": "95b2e794"
   },
   "outputs": [],
   "source": [
    "    # we define 'process' which is actually the link between the offline model we make & online live streaming\n",
    "    # we load in our model A into the globals [my model]\n",
    "    # and use this model A to make predictions\n",
    "    # and via 'process' we try to get it online again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ec23998",
   "metadata": {
    "id": "1ec23998"
   },
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "globals()['my_model'] = None\n",
    "\n",
    "# Toy predict function that returns a random probability. Normally you'd use your loaded globals()['my_model'] here\n",
    "def predict(df):\n",
    "    return globals()['my_model'].transform(df)\n",
    "\n",
    "predict_udf = udf(predict, StringType())\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    # Utilize our predict function\n",
    "    #df_withpreds = df.withColumn(\"pred\", predict_udf(\n",
    "    #    struct([df[x] for x in df.columns])\n",
    "    #))\n",
    "    #df_withpreds.show()\n",
    "    \n",
    "    # Normally, you wouldn't use a UDF (User Defined Function) Python function to predict as we did here (you can)\n",
    "    # but an MLlib model you've built and saved with Spark\n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = pipelineFit.load(\"lrm_model.model\")\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model: \n",
    "    dataset_result = globals()['my_model'].transform(df)\n",
    "    dataset_result.select('review_id', 'review_text', 'label_code', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "197bd28b",
   "metadata": {
    "id": "197bd28b"
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 10)\n",
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "decf8f8b",
   "metadata": {
    "id": "decf8f8b"
   },
   "outputs": [],
   "source": [
    "### earlier, we defined 'process' which is actually the link between the offline model we make & online live streaming\n",
    "\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d085964",
   "metadata": {
    "id": "9d085964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2023-05-28 17:42:20 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|824600|    1|139152723|A very fun and fu...|\n",
      "|824600|    1|139152686|Easily the best b...|\n",
      "|824600|    1|139152124|very well made sh...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+---------+--------------------+----------+----------+\n",
      "|review_id|         review_text|label_code|prediction|\n",
      "+---------+--------------------+----------+----------+\n",
      "|139152723|A very fun and fu...|       0.0|       0.0|\n",
      "|139152686|Easily the best b...|       0.0|       0.0|\n",
      "|139152124|very well made sh...|       0.0|       0.0|\n",
      "+---------+--------------------+----------+----------+\n",
      "\n",
      "========= 2023-05-28 17:42:30 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "| 705040|    0|139152760|#TLDR:   Hawken: ...|\n",
      "| 705040|    1|139148742|Ignore the idiots...|\n",
      "|1268750|    1|139153706|i love the game i...|\n",
      "|1268750|    1|139153191|THE ONLY GOOD BUG...|\n",
      "|1268750|    1|139153152|I'm STILL DOING M...|\n",
      "|1268750|    1|139152961|I saw my best fri...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+---------+--------------------+----------+----------+\n",
      "|review_id|         review_text|label_code|prediction|\n",
      "+---------+--------------------+----------+----------+\n",
      "|139152760|#TLDR:   Hawken: ...|       1.0|       0.0|\n",
      "|139148742|Ignore the idiots...|       0.0|       1.0|\n",
      "|139153706|i love the game i...|       0.0|       0.0|\n",
      "|139153191|THE ONLY GOOD BUG...|       0.0|       0.0|\n",
      "|139153152|I'm STILL DOING M...|       0.0|       0.0|\n",
      "|139152961|I saw my best fri...|       0.0|       0.0|\n",
      "+---------+--------------------+----------+----------+\n",
      "\n",
      "========= 2023-05-28 17:42:40 =========\n",
      "+-------+-----+---------+--------------------+\n",
      "| app_id|label|review_id|         review_text|\n",
      "+-------+-----+---------+--------------------+\n",
      "|1268750|    1|139152824|Good old spray an...|\n",
      "+-------+-----+---------+--------------------+\n",
      "\n",
      "+---------+--------------------+----------+----------+\n",
      "|review_id|         review_text|label_code|prediction|\n",
      "+---------+--------------------+----------+----------+\n",
      "|139152824|Good old spray an...|       0.0|       0.0|\n",
      "+---------+--------------------+----------+----------+\n",
      "\n",
      "========= 2023-05-28 17:43:00 =========\n",
      "+------+-----+---------+--------------------+\n",
      "|app_id|label|review_id|         review_text|\n",
      "+------+-----+---------+--------------------+\n",
      "|824600|    1|139152723|A very fun and fu...|\n",
      "|824600|    1|139152686|Easily the best b...|\n",
      "|824600|    1|139152124|very well made sh...|\n",
      "+------+-----+---------+--------------------+\n",
      "\n",
      "+---------+--------------------+----------+----------+\n",
      "|review_id|         review_text|label_code|prediction|\n",
      "+---------+--------------------+----------+----------+\n",
      "|139152723|A very fun and fu...|       0.0|       0.0|\n",
      "|139152686|Easily the best b...|       0.0|       0.0|\n",
      "|139152124|very well made sh...|       0.0|       0.0|\n",
      "+---------+--------------------+----------+----------+\n",
      "\n",
      "========= 2023-05-28 17:43:10 =========\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a82f6a",
   "metadata": {
    "id": "d6a82f6a"
   },
   "outputs": [],
   "source": [
    "ssc_t.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
